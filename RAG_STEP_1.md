# 🚀 RAG Реализация - Шаг 1: Базовая инфраструктура

## ✅ Что сделано

### 1. Модуль `lib/llm.ts` - Интеграция с Claude API
**Что внутри:**
- ✅ `askClaude()` - основная функция для запросов к Claude
- ✅ `askClaudeSimple()` - простой вопрос без контекста
- ✅ `askClaudeWithRAG()` - вопрос с контекстом из документов
- ✅ Обработка ошибок и логирование
- ✅ Подсчёт использованных токенов

**Ключевые моменты:**
```typescript
// Без RAG - просто вопрос
await askClaudeSimple("Что такое машинное обучение?");

// С RAG - вопрос + контекст из документов
await askClaudeWithRAG(
  "Что такое машинное обучение?",
  "Контекст: ML - это раздел AI..."
);
```

### 2. Модуль `lib/rag.ts` - RAG логика
**Что внутри:**
- ✅ `formatContextForLLM()` - форматирует чанки в читаемый контекст
- ✅ `extractSourcesInfo()` - извлекает метаданные об источниках
- ✅ `evaluateContextQuality()` - оценивает качество найденного
- ✅ `prepareContextWithLimit()` - ограничивает размер контекста

**Пример использования:**
```typescript
// Есть результаты поиска
const searchResults = [...]; // из semantic search

// Форматируем для LLM
const context = formatContextForLLM(searchResults);

// Оцениваем качество
const quality = evaluateContextQuality(searchResults);
// quality: { confidence: 0.9, recommendation: "..." }

// Извлекаем источники
const sources = extractSourcesInfo(searchResults);
// sources: { total_sources: 2, sources: [...] }
```

### 3. Обновлён `.env.example`
Добавлена переменная для API ключа:
```
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxx
```

---

## 🎯 Что это даёт?

### Без этих модулей:
```
[Поиск] → [Результаты] → ❌ Дальше ничего
```

### С этими модулями:
```
[Поиск] → [Результаты] → [Форматирование] → [LLM] → ✅ Умный ответ
```

---

## 📚 Как это работает (архитектура)

```
┌─────────────────────────────────────────────────────┐
│                   Пользователь                      │
│            "Что такое машинное обучение?"           │
└────────────────────┬────────────────────────────────┘
                     │
                     ↓
┌─────────────────────────────────────────────────────┐
│              Semantic Search (уже есть)              │
│  Ищет релевантные чанки в индексе                   │
└────────────────────┬────────────────────────────────┘
                     │
                     ↓
┌─────────────────────────────────────────────────────┐
│              lib/rag.ts (НОВОЕ!)                     │
│  - formatContextForLLM() - форматирует чанки        │
│  - evaluateContextQuality() - оценивает качество    │
└────────────────────┬────────────────────────────────┘
                     │
                     ↓
┌─────────────────────────────────────────────────────┐
│              lib/llm.ts (НОВОЕ!)                     │
│  - askClaudeWithRAG() - отправляет в Claude         │
│  - Вопрос + Контекст → Claude API                   │
└────────────────────┬────────────────────────────────┘
                     │
                     ↓
┌─────────────────────────────────────────────────────┐
│                  Claude AI                           │
│  Генерирует ответ на основе документов              │
└────────────────────┬────────────────────────────────┘
                     │
                     ↓
┌─────────────────────────────────────────────────────┐
│                    Ответ                             │
│  "Согласно вашим документам, машинное обучение..."  │
└─────────────────────────────────────────────────────┘
```

---

## 🔧 Настройка (что нужно сделать СЕЙЧАС)

### 1. Получить API ключ Claude

1. Зайдите на https://console.anthropic.com/
2. Создайте аккаунт или войдите
3. Перейдите в Settings → API Keys
4. Нажмите "Create Key"
5. Скопируйте ключ (начинается с `sk-ant-`)

### 2. Добавить в проект

Создайте файл `.env.local` в корне проекта:

```bash
# В корне semantic-search-app/
touch .env.local
```

Добавьте в него:
```
ANTHROPIC_API_KEY=sk-ant-ваш-ключ-здесь
```

### 3. Перезапустить сервер

```bash
# Ctrl+C чтобы остановить
# Затем запустить снова
npm run dev
```

---

## ✅ Проверка работы

Давайте проверим что модули работают. Создайте тестовый файл:

```typescript
// test-llm.ts (временный файл для теста)
import { askClaudeSimple } from './lib/llm';

async function test() {
  const answer = await askClaudeSimple("Привет! Как дела?");
  console.log("Ответ Claude:", answer);
}

test();
```

Запустите:
```bash
npx tsx test-llm.ts
```

Если увидите ответ от Claude - всё работает! ✅

---

## 🎓 Что дальше?

### ✅ Шаг 1 (ГОТОВ): Базовая инфраструктура
- lib/llm.ts - работа с Claude API
- lib/rag.ts - RAG логика

### 🔄 Шаг 2 (СЛЕДУЮЩИЙ): API Endpoint
Создадим `/api/rag/route.ts` который:
- Принимает вопрос пользователя
- Ищет релевантные чанки
- Отправляет в Claude
- Возвращает ответ

### 🔜 Шаг 3: Режим сравнения
Сделаем два режима (с RAG / без RAG) параллельно

### 🔜 Шаг 4: UI для сравнения
Красивый интерфейс с двумя колонками

---

## 💡 Важные моменты

### Токены и лимиты
- Claude API считает входные и выходные токены
- ~1 токен = ~4 символа
- Лимит контекста: 200K токенов (очень много!)
- Мы ограничиваем контекст до 8000 символов (~2000 токенов)

### Стоимость (примерно)
- Claude 3.5 Sonnet: $3 за 1M входных токенов, $15 за 1M выходных
- Один запрос (~2000 вх + 500 вых токенов) ≈ $0.01
- То есть очень дёшево!

### Качество контекста
Функция `evaluateContextQuality()` помогает понять:
- **High** (0.7+): отличный контекст, ответ будет точным
- **Medium** (0.5-0.7): неплохой контекст, ответ может быть неполным
- **Low** (<0.5): слабый контекст, лучше использовать без RAG

---

## 🐛 Troubleshooting

### Ошибка: "ANTHROPIC_API_KEY не установлен"
```bash
# Проверьте файл .env.local
cat .env.local

# Убедитесь что ключ там есть
# Перезапустите сервер
```

### Ошибка: "Claude API error: 401"
Неверный API ключ. Проверьте:
- Ключ скопирован полностью
- Нет лишних пробелов
- Ключ активен на console.anthropic.com

### Ошибка: "Rate limit exceeded"
Слишком много запросов. Подождите минуту.

---

## 📝 Следующий шаг

Когда будешь готов, скажи **"Шаг 2"** и я создам API endpoint!

Он будет объединять всё:
1. Получать вопрос от пользователя
2. Искать в документах (semantic search)
3. Форматировать контекст (lib/rag.ts)
4. Отправлять в Claude (lib/llm.ts)
5. Возвращать ответ

**Готов продолжить?** 🚀
